{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IonLipnL32DE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matth\\anaconda3\\envs\\py311_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageFilter\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device : []\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"GPU device :\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPU is unavailable \n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"✅ GPU is available\")\n",
    "else:\n",
    "    print(\"❌ GPU is unavailable \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "20LZMn2F32DG",
    "outputId": "9eae5392-25bd-49e5-db69-ffddf5161bf8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas :  1\n",
      "Tensorflow :  2.15.0\n",
      "Python :  3.11.13\n",
      "Num GPUs Available :  0\n",
      "Using device :  \n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas : \", strategy.num_replicas_in_sync)\n",
    "print('Tensorflow : ',tf.__version__)\n",
    "print('Python : ',sys.version.split()[0])\n",
    "print(\"Num GPUs Available : \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Using device : \", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4330845919668094905\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_jpg_directory = r'D:\\MATTHEW\\Data Modelling\\gan-getting-started\\monet_jpg'\n",
    "photo_jpg_directory = r'D:\\MATTHEW\\Data Modelling\\gan-getting-started\\photo_jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EZHFigpEUz-A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monet images: 300\n",
      "Photo images: 7038\n"
     ]
    }
   ],
   "source": [
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "monet_images_path = getImagePaths(monet_jpg_directory)\n",
    "photo_images_path = getImagePaths(photo_jpg_directory)\n",
    "\n",
    "print(f\"Monet images: {len(monet_images_path)}\")\n",
    "print(f\"Photo images: {len(photo_images_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "class InstanceNormalization(layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super(InstanceNormalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma',shape=(input_shape[-1],),initializer='ones',trainable=True)\n",
    "        self.beta = self.add_weight(name='beta',shape=(input_shape[-1],),initializer='zeros',trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        return self.gamma * (x - mean) / tf.sqrt(variance + self.epsilon) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nq6ip1eP32DV"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256]) \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "# Batch and shuffle\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "monet_ds = tf.data.Dataset.from_tensor_slices(monet_images_path)\n",
    "monet_ds = monet_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "monet_ds = monet_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "photo_ds = tf.data.Dataset.from_tensor_slices(photo_images_path)\n",
    "photo_ds = photo_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "photo_ds = photo_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# Downsampling block\n",
    "def downsample(filters, size, apply_instancenorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    if apply_instancenorm:\n",
    "        result.add(InstanceNormalization())\n",
    "    result.add(layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "# Upsampling block\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(InstanceNormalization())\n",
    "    if apply_dropout:\n",
    "        result.add(layers.Dropout(0.5))\n",
    "    result.add(layers.ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S0rvCsUe32DV"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(32, 4, apply_instancenorm=False),\n",
    "        downsample(64, 4),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "    ]\n",
    "\n",
    "    res_blocks = [layers.Conv2D(512, 3, strides=1, padding='same',\n",
    "                                 activation='relu',\n",
    "                                 kernel_initializer=tf.random_normal_initializer(0., 0.02)) for _ in range(2)]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4),\n",
    "        upsample(32, 4),\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same',\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  activation='tanh')\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    for res in res_blocks:\n",
    "        x = res(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "    return Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bxOV_tgv32DV"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    x = inp\n",
    "\n",
    "    down1 = downsample(64, 4, apply_instancenorm=False)(x)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "\n",
    "    zero_pad1 = layers.ZeroPadding2D()(down3)\n",
    "    conv = layers.Conv2D(512, 4, strides=1, padding='valid',kernel_initializer=initializer, use_bias=False)(zero_pad1)\n",
    "    norm1 = InstanceNormalization()(conv)\n",
    "    leaky_relu = layers.LeakyReLU()(norm1)\n",
    "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n",
    "    last = layers.Conv2D(1, 4, strides=1, padding='valid',kernel_initializer=initializer)(zero_pad2)\n",
    "\n",
    "    return Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hZdq_FFw32DW",
    "outputId": "4005e6ce-d643-4166-f322-9558dda862c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING:tensorflow:From C:\\Users\\matth\\anaconda3\\envs\\py311_env\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate models\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    monet_generator = Generator()\n",
    "    photo_generator = Generator()\n",
    "    monet_discriminator = Discriminator()\n",
    "    photo_discriminator = Discriminator()\n",
    "\n",
    "# Loss functions\n",
    "with strategy.scope():\n",
    "    loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    real_loss = tf.reduce_mean(loss_obj(tf.ones_like(real), real))\n",
    "    generated_loss = tf.reduce_mean(loss_obj(tf.zeros_like(generated), generated))\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return tf.reduce_mean(loss_obj(tf.ones_like(generated), generated))\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image, LAMBDA=10):\n",
    "    l1_loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    l2_loss = tf.reduce_mean(tf.square(real_image - cycled_image))\n",
    "    return LAMBDA * (0.9 * l1_loss + 0.1 * l2_loss)\n",
    "\n",
    "def identity_loss(real_image, same_image, LAMBDA=5):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss\n",
    "\n",
    "# Learning rate scheduler\n",
    "initial_learning_rate = 2e-4\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[50 * (len(monet_images_path) // BATCH_SIZE), 75 * (len(monet_images_path) // BATCH_SIZE)],\n",
    "    values=[initial_learning_rate, initial_learning_rate * 0.1, initial_learning_rate * 0.01]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hfxbI4tc32DW"
   },
   "outputs": [],
   "source": [
    "# Optimizers with gradient clipping\n",
    "with strategy.scope():\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_monet, real_photo):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        fake_monet = monet_generator(real_photo, training=True)\n",
    "        cycled_photo = photo_generator(fake_monet, training=True)\n",
    "        fake_photo = photo_generator(real_monet, training=True)\n",
    "        cycled_monet = monet_generator(fake_photo, training=True)\n",
    "        same_monet = monet_generator(real_monet, training=True)\n",
    "        same_photo = photo_generator(real_photo, training=True)\n",
    "        disc_real_monet = monet_discriminator(real_monet, training=True)\n",
    "        disc_real_photo = photo_discriminator(real_photo, training=True)\n",
    "        disc_fake_monet = monet_discriminator(fake_monet, training=True)\n",
    "        disc_fake_photo = photo_discriminator(fake_photo, training=True)\n",
    "        monet_gen_loss = generator_loss(disc_fake_monet)\n",
    "        photo_gen_loss = generator_loss(disc_fake_photo)\n",
    "        total_cycle_loss = calc_cycle_loss(real_monet, cycled_monet) + calc_cycle_loss(real_photo, cycled_photo)\n",
    "        total_monet_gen_loss = monet_gen_loss + total_cycle_loss + identity_loss(real_monet, same_monet)\n",
    "        total_photo_gen_loss = photo_gen_loss + total_cycle_loss + identity_loss(real_photo, same_photo)\n",
    "        monet_disc_loss = discriminator_loss(disc_real_monet, disc_fake_monet)\n",
    "        photo_disc_loss = discriminator_loss(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "    monet_generator_gradients = tape.gradient(total_monet_gen_loss, monet_generator.trainable_variables)\n",
    "    photo_generator_gradients = tape.gradient(total_photo_gen_loss, photo_generator.trainable_variables)\n",
    "    monet_discriminator_gradients = tape.gradient(monet_disc_loss, monet_discriminator.trainable_variables)\n",
    "    photo_discriminator_gradients = tape.gradient(photo_disc_loss, photo_discriminator.trainable_variables)\n",
    "\n",
    "    monet_generator_optimizer.apply_gradients(zip(monet_generator_gradients, monet_generator.trainable_variables))\n",
    "    photo_generator_optimizer.apply_gradients(zip(photo_generator_gradients, photo_generator.trainable_variables))\n",
    "    monet_discriminator_optimizer.apply_gradients(zip(monet_discriminator_gradients, monet_discriminator.trainable_variables))\n",
    "    photo_discriminator_optimizer.apply_gradients(zip(photo_discriminator_gradients, photo_discriminator.trainable_variables))\n",
    "\n",
    "    return total_monet_gen_loss, total_photo_gen_loss, monet_disc_loss, photo_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wdumxetV32DW",
    "outputId": "78a81c2a-64e1-455c-d953-15b17dd5cc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "391.12s Avg Monet Gen Loss : 5.0866, Avg Photo Gen Loss : 5.0989, Avg Monet Disc Loss : 0.6898, Avg Photo Disc Loss : 0.6960\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'monet_gen_loss': [],\n",
    "    'photo_gen_loss': [],\n",
    "    'monet_disc_loss': [],\n",
    "    'photo_disc_loss': []\n",
    "}\n",
    "\n",
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    start_time = time.time()\n",
    "    total_monet_gen_loss = 0\n",
    "    total_photo_gen_loss = 0\n",
    "    total_monet_disc_loss = 0\n",
    "    total_photo_disc_loss = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    for real_monet, real_photo in tf.data.Dataset.zip((monet_ds, photo_ds)):\n",
    "        monet_gen_loss, photo_gen_loss, monet_disc_loss, photo_disc_loss = train_step(real_monet, real_photo)\n",
    "        total_monet_gen_loss += monet_gen_loss.numpy()\n",
    "        total_photo_gen_loss += photo_gen_loss.numpy()\n",
    "        total_monet_disc_loss += monet_disc_loss.numpy()\n",
    "        total_photo_disc_loss += photo_disc_loss.numpy()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_monet_gen_loss = total_monet_gen_loss / n_batches\n",
    "    avg_photo_gen_loss = total_photo_gen_loss / n_batches\n",
    "    avg_monet_disc_loss = total_monet_disc_loss / n_batches\n",
    "    avg_photo_disc_loss = total_photo_disc_loss / n_batches\n",
    "\n",
    "    history['monet_gen_loss'].append(avg_monet_gen_loss)\n",
    "    history['photo_gen_loss'].append(avg_photo_gen_loss)\n",
    "    history['monet_disc_loss'].append(avg_monet_disc_loss)\n",
    "    history['photo_disc_loss'].append(avg_photo_disc_loss)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"{elapsed_time:.2f}s\" , f\"Avg Monet Gen Loss : {avg_monet_gen_loss:.4f}, Avg Photo Gen Loss : {avg_photo_gen_loss:.4f}, \"\n",
    "          f\"Avg Monet Disc Loss : {avg_monet_disc_loss:.4f}, Avg Photo Disc Loss : {avg_photo_disc_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ao7ORqqp32DX",
    "outputId": "d32abe57-a370-44ba-85cb-9c8648187f04"
   },
   "outputs": [],
   "source": [
    "def plot_generator_loss(history):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    epochs = range(len(history['monet_gen_loss']))\n",
    "    xticks = list(range(0, len(epochs), 2))\n",
    "    if (len(epochs) - 1) not in xticks:\n",
    "        xticks.append(len(epochs))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['monet_gen_loss'], label='Monet Generator Loss', color='orange', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Monet Generator Loss')\n",
    "    plt.xticks(xticks)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['photo_gen_loss'], label='Photo Generator Loss', color='blue', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Photo Generator Loss')\n",
    "    plt.xticks(xticks)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_generator_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhzeitCT32Db",
    "outputId": "17dafd51-5409-4d9b-c385-aca13aed1e2b"
   },
   "outputs": [],
   "source": [
    "def plot_discriminator_loss(history):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    epochs = range(len(history['monet_disc_loss']))\n",
    "    xticks = list(range(0, len(epochs), 2))\n",
    "    if (len(epochs) - 1) not in xticks:\n",
    "        xticks.append(len(epochs))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['monet_disc_loss'], label='Monet Discriminator Loss', color='orange', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Monet Discriminator Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['photo_disc_loss'], label='Photo Discriminator Loss', color='blue', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Photo Discriminator Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_discriminator_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VZQ0jGF32Dc"
   },
   "outputs": [],
   "source": [
    "def display_generated_images_SSIM(photo_ds, num_images=5, start_from=1):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    ssim_scores = []\n",
    "    selected_photos = photo_ds.skip(start_from - 1).take(num_images)\n",
    "\n",
    "    for i, photo in enumerate(selected_photos):\n",
    "        fake_monet = monet_generator(photo, training=False)\n",
    "        fake_monet_rescaled = (fake_monet[0] * 0.5 + 0.5).numpy()\n",
    "        photo_rescaled = (photo[0] * 0.5 + 0.5).numpy()\n",
    "        ssim_score = tf.image.ssim(photo_rescaled, fake_monet_rescaled, max_val=1.0).numpy()\n",
    "        ssim_percent = ssim_score * 100\n",
    "        ssim_scores.append(ssim_percent)\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(photo_rescaled)\n",
    "        plt.title(f\"Original Photo\", fontsize=20)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(fake_monet_rescaled)\n",
    "        plt.title(f\"Monet Style\\nSSIM : {ssim_percent:.3f}%\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "    return ssim_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_1 = display_generated_images_SSIM(photo_ds, num_images=5, start_from=1)\n",
    "print(\" \" * 100)\n",
    "ssim_2 = display_generated_images_SSIM(photo_ds, num_images=5, start_from=6)\n",
    "print(\" \" * 100)\n",
    "ssim_3 = display_generated_images_SSIM(photo_ds, num_images=5, start_from=11)\n",
    "print(\" \" * 100)\n",
    "\n",
    "all_ssim = ssim_1 + ssim_2 + ssim_3\n",
    "avg_ssim_all = sum(all_ssim) / len(all_ssim)\n",
    "plt.figure(figsize=(20, 1))\n",
    "plt.axis('off')\n",
    "plt.figtext(0.5, 0.5, f\"Average SSIM : {avg_ssim_all:.3f}%\", ha='center', fontsize=20, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkk07xs1-akg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpu-py310-env]",
   "language": "python",
   "name": "conda-env-gpu-py310-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
